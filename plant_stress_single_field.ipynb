{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import geojson\n",
    "import geopandas as gpd\n",
    "import shapely.wkt\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import re \n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from geojson import Feature\n",
    "from sentinel2download.downloader import Sentinel2Downloader\n",
    "from sentinel2download.overlap import Sentinel2Overlap\n",
    "\n",
    "from code.index_research import calculate_ndvi\n",
    "from code.plant_stress import PlantStress\n",
    "from code.utils import stitch_tiles\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUEST_ID=os.getenv('REQUEST_ID')\n",
    "START_DATE=os.getenv('START_DATE')\n",
    "END_DATE=os.getenv('END_DATE')\n",
    "AOI=os.getenv('AOI')\n",
    "SENTINEL2_GOOGLE_API_KEY=os.getenv('SENTINEL2_GOOGLE_API_KEY')\n",
    "SATELLITE_CACHE_FOLDER=os.getenv('SENTINEL2_CACHE')\n",
    "OUTPUT_FOLDER=os.getenv('OUTPUT_FOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_crs = 'EPSG:4326'\n",
    "\n",
    "polygon_aoi = shapely.wkt.loads(AOI)\n",
    "aoi_filename = f\"{time.time()}_aoi.geojson\"\n",
    "aoi_gdf = gpd.GeoDataFrame(gpd.GeoSeries([polygon_aoi]), columns=[\"geometry\"], crs=default_crs)\n",
    "aoi_gdf.to_file(aoi_filename, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = os.getcwd()\n",
    "BANDS = {'B04', 'B08', 'CLD'}\n",
    "NODATA_PIXEL_PERCENTAGE = 10.0\n",
    "SEARCH_CLOUDY_PIXEL_PERCENTAGE = 50.0\n",
    "AOI_CLOUDY_PIXEL_PERCENTAGE = 15.0\n",
    "CONSTRAINTS = {'CLOUDY_PIXEL_PERCENTAGE': SEARCH_CLOUDY_PIXEL_PERCENTAGE}\n",
    "PRODUCT_TYPE = 'L2A'\n",
    "NAME = 'Field anomalies'\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b04_tiles, b08_tiles, tci_tiles = [], [], []\n",
    "s2overlap = Sentinel2Overlap(aoi_path=aoi_filename)\n",
    "overlap_tiles = s2overlap.overlap_with_geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_no_data_geojson(polygon, geojson_path):\n",
    "    NO_DATA = 'No data'\n",
    "    style = dict(color='red')\n",
    "    feature = Feature(geometry=polygon, properties=dict(label=NO_DATA, style=style))\n",
    "    feature['start_date'] = START_DATE\n",
    "    feature['end_date'] = END_DATE\n",
    "    feature['name'] = NO_DATA\n",
    "    \n",
    "    with open(geojson_path, 'w') as f:\n",
    "        geojson.dump(feature, f)\n",
    "\n",
    "def check_nodata_percentage_crop(tile_path, \n",
    "                                 aoi, \n",
    "                                 nodata_percentage_limit, \n",
    "                                 nodata):\n",
    "    with rasterio.open(tile_path) as src:\n",
    "        polygon = aoi.to_crs(src.meta['crs']).geometry[0]\n",
    "        band, _ = rasterio.mask.mask(src, [polygon], crop=True, filled=False, indexes=1)\n",
    "        masked_band = band[~band.mask]\n",
    "        nodata_count = np.count_nonzero(masked_band == nodata)\n",
    "        nodata_percentage = round(nodata_count / masked_band.size * 100, 2)\n",
    "    if nodata_percentage>=nodata_percentage_limit:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_cloud_percentage_crop(tile_path, \n",
    "                                aoi, \n",
    "                                cloud_percentage_limit,\n",
    "                                cloud_probability=50):\n",
    "    with rasterio.open(tile_path) as src:\n",
    "        polygon = aoi.to_crs(src.meta['crs']).geometry[0]\n",
    "        band, _ = rasterio.mask.mask(src, [polygon], crop=True, filled=False, indexes=1)\n",
    "        masked_band = band[~band.mask]\n",
    "        cloud_count = np.count_nonzero(masked_band >= cloud_probability)\n",
    "        cloud_percentage = round(cloud_count / masked_band.size * 100, 2)\n",
    "    if cloud_percentage>=cloud_percentage_limit:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_tile_validity(tile_folder, aoi, cloud_percentage_limit, nodata_percentage_limit):\n",
    "    band_paths = [os.path.join(tile_folder, i) for i in os.listdir(tile_folder)]\n",
    "    skip_tile = False\n",
    "    for band_path in band_paths:\n",
    "        if  '.jp2' != Path(band_path).suffix:\n",
    "            continue\n",
    "        if \"MSK_CLDPRB_20m\" in band_path:\n",
    "            cloud_check = check_cloud_percentage_crop(band_path, aoi, cloud_percentage_limit)\n",
    "            if cloud_check:\n",
    "                skip_tile=True\n",
    "                break\n",
    "        else:\n",
    "            nodata_check = check_nodata_percentage_crop(band_path, aoi, nodata_percentage_limit, 0)\n",
    "            if nodata_check:\n",
    "                skip_tile=True\n",
    "                break\n",
    "    return skip_tile, band_paths\n",
    "\n",
    "def validate_tile_downloads(loaded, tile, loadings, aoi, cloud_percentage_limit, nodata_percentage_limit):\n",
    "    print(f\"Validating images for tile: {tile}...\")\n",
    "    if not loaded:\n",
    "        print(f\"Images for tile {tile} were not loaded!\")\n",
    "        return loadings\n",
    "    loaded_tile_folders = set([Path(i[0]).parent for i in loaded])\n",
    "    tile_bands = []\n",
    "    for loaded_tile_folder in loaded_tile_folders:\n",
    "        skip_tile, band_paths = check_tile_validity(loaded_tile_folder, aoi, cloud_percentage_limit, nodata_percentage_limit)\n",
    "        if skip_tile:\n",
    "            shutil.rmtree(loaded_tile_folder)\n",
    "        else:\n",
    "            tile_bands += band_paths\n",
    "    if tile_bands:\n",
    "        loadings[tile] = tile_bands\n",
    "    else:\n",
    "        print(f\"Tile images didn't match nodata/cloud constraints, so they were removed\") \n",
    "    print(f\"Validating images for tile {tile} finished\")  \n",
    "    return loadings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(tiles, start_date, end_date, aoi):\n",
    "    loader = Sentinel2Downloader(SENTINEL2_GOOGLE_API_KEY)\n",
    "    loadings = dict()\n",
    "\n",
    "    for tile in tiles:\n",
    "        print(f\"Loading images for tile: {tile}...\")\n",
    "        loaded = loader.download(PRODUCT_TYPE,\n",
    "                            [tile],\n",
    "                            start_date=start_date,\n",
    "                            end_date=end_date,\n",
    "                            output_dir=SATELLITE_CACHE_FOLDER,               \n",
    "                            bands=BANDS,\n",
    "                            constraints=CONSTRAINTS)\n",
    "        print(f\"Loading images for tile {tile} finished\")\n",
    "        loadings = validate_tile_downloads(loaded, tile, loadings, aoi, AOI_CLOUDY_PIXEL_PERCENTAGE, NODATA_PIXEL_PERCENTAGE)\n",
    "    return loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = load_images(overlap_tiles.Name.values, START_DATE, END_DATE, aoi_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_date(loadings):\n",
    "    def _find_last_date(folders):        \n",
    "        dates = list()\n",
    "        for folder in folders:        \n",
    "            search = re.search(r\"_(\\d+)T\\d+_\", str(folder))\n",
    "            date = search.group(1)\n",
    "            date = datetime.strptime(date, '%Y%m%d')\n",
    "            dates.append(date)    \n",
    "        last_date = max(dates)\n",
    "        last_date = datetime.strftime(last_date, '%Y%m%d')\n",
    "        return last_date\n",
    "    \n",
    "    filtered = {\n",
    "        'BO4': [],\n",
    "        'BO8': []\n",
    "    }\n",
    "    for tile, items in loadings.items():\n",
    "        try:\n",
    "            last_date = _find_last_date(items)\n",
    "            for path in items:\n",
    "                if last_date in path:\n",
    "                    if 'B04_10m.jp2' in path:\n",
    "                        filtered['BO4'] += [path]\n",
    "                    if 'B08_10m.jp2' in path:\n",
    "                        filtered['BO8'] += [path]\n",
    "        except Exception as ex:\n",
    "            print(f\"Error for {tile}: {str(ex)}\")\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filter_by_date(loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not filtered['BO4'] or not filtered['BO8']:\n",
    "    geojson_path = os.path.join(OUTPUT_FOLDER, f\"{START_DATE}_{END_DATE}_no_data.geojson\")\n",
    "    dump_no_data_geojson(aoi_gdf.geometry[0], geojson_path)\n",
    "    raise ValueError(\"Images not loaded for given AOI. Change dates, constraints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(filtered['BO4']) > 1:\n",
    "    b04_tile = stitch_tiles(filtered['BO4'], filtered['BO4'][0].replace('.jp2', '_merged.tif'))\n",
    "    b08_tile = stitch_tiles(filtered['BO8'], filtered['BO8'][0].replace('.jp2', '_merged.tif'))\n",
    "else:\n",
    "    b04_tile = filtered['BO4'][0]\n",
    "    b08_tile = filtered['BO8'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_path = os.path.join(BASE, f'{START_DATE}_{END_DATE}_ndvi.tif')\n",
    "if not os.path.exists(ndvi_path):\n",
    "    calculate_ndvi(b04_tile, b08_tile, out_path=ndvi_path, nodata=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ndvi = 0.3\n",
    "z_score = 5\n",
    "z_score_anom = 1\n",
    "colors = {\"Normal Growth\": (0, 0, 0), \"Anomaly\": (182, 10, 28)}\n",
    "\n",
    "field = gpd.read_file(aoi_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PlantStress(min_ndvi=min_ndvi, noise_z_score=z_score, anomaly_z_score=z_score_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_path = os.path.join(OUTPUT_FOLDER, f'{START_DATE}_{END_DATE}_field.tif')\n",
    "ps.segment_field(NAME, field, ndvi_path, raster_path, START_DATE, END_DATE, REQUEST_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
